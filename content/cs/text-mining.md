---
title: "텍스트 마이닝 - Text Mining"
date: 2020-03-22T11:32:46+09:00
---

# 텍스트 마이닝 - Text Mining

[1. 필요 요구 사항](##-1.-필요-요구-사항)  
[2. 텍스트 마이닝 소개](##-2.-텍스트-마이닝-소개)  
[3. 텍스트 마이닝의 이해](##-3.-텍스트-마이닝의-이해)  
[4. 텍스트 마이닝 기법 소개](##-4.-텍스트-마이닝-기법-소개)  
[5. 텍스트 표현의 단위](##-5.-텍스트-표현의-단위)  
[6. Character 단위 분석](##-6.-Character-단위-분석)  
[7. 단어 단위 텍스트 분석](##-7.-단어-단위-텍스트-분석)  
[8. Zipf’s 법칙](##-8.-Zipf’s-법칙)  
[9. 구 단위 텍스트 분석](##-9.-구-단위-텍스트-분석)  

## 1. 필요 요구 사항

- 자바는 프로그래밍 언어
	- 자바로 쓰인 고급 프로그래밍 언어
	- 자바와 기계 코드를 돌리기 위해 자바 컴파일러와 가상 머신을 사용함
- Java JDK
- Eclipse
- yTextMiner

## 2. 텍스트 마이닝 소개

- 대량의 텍스트 데이터셋에서 흥미로운 규칙들을 찾아내는 것(Usama Fayad)
- 문자로 된 다른 자료들로부터 자동적으로 정보를 추출하는, 이전에 알려지지 않은 새로운 정보의 발견 (Hearst, 2003)

### 마이닝 방법론

- 비정형 텍스트에서 흥미롭고 의미 있는 정보를 발견하는 연구영역
- 특정한 목적에 대해 의미 있는 정보를 추출하는 일련의 텍스트 분석 및 처리과정을 통해 이루어짐
- 비정형화 데이터가 차지하고 있는 비율은 세상에 존재하는 데이터 중 70~80% 이상(Chakraborty, 2014)
- IDC의 Digital Universe Study에서는 2010년대 초반의 전 세계 비정형 데이터의 총규모는 1.8제타바이트(zettabytes)
- 2020년에는 약 40제타바이트로 증가할 것으로 예측

### 마이닝 소스(원천 데이터)

- 웹 상에서 텍스트 데이터의 증가
	- 웹사이트 증가
- 기타 텍스트 형식의 정보 유형
	- 신문
	- 잡지
	- 문서
	- 이메일
	- 블로그 포스트
	- 트위터

### 소결론

- 텍스트 마이닝은 다양한 영역에서 사용되고 있으며,
- 그 중요도가 비정형 데이터의 증가와 맞물려 증대될 것임

## 3. 텍스트 마이닝의 이해

> 표현 방법 - 낱글자, 단어  
> 기법적인 방법 - 지도 학습, 비지도 학습  
> 수행(task)하는 임무 차원에서의 방법 - 문헌 자동 분류, 자동 요약, Topic Modeling, 감성 분석

- 텍스트 분석의 접근 방법
	- 1) 요소 단위에 따른 접근
		- 텍스트 분석의 요소 단위(element)에 따르는 접근
		- 문자 수준(character level), 단어 수준, 구 수준
		- 문장 수준, 초록 수준, 전문 수준, 전체 문헌집단 수준까지 광범위함
	- 2) 기법적인 측면의 접근
		- 텍스트 분석에 어떤 기법이 적용되는지에 대한 접근
		- 수작업 태깅에서부터 추론학습까지 여러 가지 텍스트 분석 기법이 존재함
	- 3) 임무 수행 측면의 접근
		- 어떤 임무를 수행하느냐에 따르는 접근
		- 정보검색에서부터 비지도 기반, 반지도 기반, 지도 기반의 기계학습
		- 시각화, 요약, 번역에 이르기까지 다양함

### 3가지 주요 접근 방법

- 기술적(Descriptive) 분석
	- 데이터를 이해 - 대부분의 미가공 데이터는 사람들이 쓰기에 적합하지
		않지만 데이터에서 끌어낸 정보는 적합함
	- 대량의 데이터를 더 작고 유용한 정보의 알맹이로 압축할 수 있음
	- 일어난 일을 요약함
	- 비즈니스 분석의 80% 이상은 (대부분 특히 소셜 분석) 기술적임
	- 예시로는 많은 포스트, 멘션, 팬들, 팔로워들, 페이지 뷰 횟수, 체크인 횟수 등이 있음
	- 우리는 수 많은 데이터들을 가지고 있다. 그것으로 무엇을 할 수 있는가?
- 예측적(Predictive) 분석
	- 모든 예측 분석은 현실적으로 개연성 있기 때문에 미래에 일어날 만한 것을 예측
	- 과거와 최근의 데이터를 연구하기 위해 여러 통계, 모델링, 데이터 마이닝, 머신러닝 기법들을 이용
	- Ex) 감성 분석 - 현재 가지고 있지 않은 sentiment label의 데이터의 sentiment가 긍정인지 부정인		지 예측
	- 뇌 종양을 일으키는 새로운 유전자들은 무엇인가?
	- 새로운 기술 트렌드 중에서 A회사가 투자해야 할 것은?
- 지시적(Prescriptive) 분석
	- 기술적, 예측적 모델을 넘어 한가지, 혹은 그 이상의 행동들을 추천하며
		각 결정의 예상 결과를 보여줌
	- 행동을 지시해야 하는 상황에 적합하며, 비즈니스 결정자가 지시된 정보를 채택하여
		실행에 옮길 수 있음
	- 지시적 모델이 각각의 행동 선택에 따라 일어날 수 있는 결과를 예측할 수 있기 때문에
		사전에 명시된 결과에 대한 가장 좋은 행동을 추천해줌
	- 빅 날리지(Big Knowledge)

### 텍스트 마이닝의 적용

- 정보 접근을 도와줌
	- 검색 결과를 더 잘 요약하기 위해 잠재하는 토픽들을 발견함
- 정보 조직을 도와줌
	- 숨겨진 구조를 찾아냄
- 시각화를 도와줌

## 4. 텍스트 마이닝 기법 소개

- 자연 언어 이해(Natural Language Understanding)
	- 챗봇
-  토픽 모델링(Topic Modeling)
	- 단어 군집, 주제적으로 군집
- 감성 분석(Sentiment Analysis)
- 문서 분류(Document Classification)
	- 기계 학습
- 집단화(Clustering)
	- 비주도 학습

### 텍스트 마이닝 단계

- 1. 데이터 수집 (Collecting Data)
	- 데이터 수집은 모든 적합한 텍스트들을 산출함
	- 수집, 선택, 필터는 유용성을 높여줌
- 2. 전처리 (Preprocessing)
	- 전처리는 다양한 텍스트들을 분석 가능한 데이터로 정제함
- 3. 텍스트 마이닝 기법 적용 (Applying Text mining Techniques)
	- 이용자에게 흥미에 대한 사실과 사건을 알려줌
	- 적절한 개념과 그에 대한 사실을 찾아냄
	- 현재 찾고 있는 것을 찾아내줌
	- 새로운 지식을 발견하고 새로운 조합을 찾아냄

### 기존 연구들

- 텍스트 마이닝 기법을 소셜미디어 텍스트에 적용
	- Factiva DB -> News Articles(4,484) -> Train Set(2,000) -> 
	- Maximum Entropy Classifier -> Test Set(2,484)
	- Sentiment Coded News Articles(4,484)
- 주제에 대한 매체 간의 차이점, 사실 관계 분석

## 5. 텍스트 표현의 단위

- 어휘(Lexical) 표현
	- 문자 (문지 기반 n-gram, 순서열)
	- 단어 (불용어, 어간 추출, 원형 복원)
	- 구 (단어 기반 n-gram, proximity features)
	- 품사 태그 (Part-of-speech(POS) tags)
- 구문 (Syntactic) 표현
	- 벡터-공간 모델 (Vector-Space Model)
	- 언어 모델 (Language Models)
	- 전체 구문 분석 (Full-parsing)
- 의미론적 표현
	-  Collaborative tagging / Web 2.0
	- Templates / Frames
	- Ontologies / First order theories

## 6. Character 단위 분석

- 어휘(Lexical) 표현
	- 문자 (문지 기반 n-gram, 순서열)
		- 낱글자로 기반으로 한 철자 오류 검사

### 문자 단위 텍스트 분석

- 텍스트 분석의 첫 번째 단위
- 문자는 글자와 구분 기호로 나누어짐

### 문자 단위의 텍스트 분석의 대표적인 예

- 문자 기반 언어 모델(Language model)
	- 통계 기반 기법으로 확률분포를 이용해서
	- m개의 단어를 문자 순열로 표현하고
	- 이에 확률를 부여하는 기법 P(w1, …, wm)
- 서픽스 배열(Suffix array)
	- 일련의 문자열의 접미사를 사전식 순서대로 나열한 배열
	- 문자열 검색이나 전문 검사 정보검색에서 색인 작업이나  
		텍스트 마이닝의 전처리 과정 등에서 쓰임

## 7. 단어 단위 텍스트 분석

- 단어 (불용어, 어간 추출, 원형 복원)

### 단어의 특징

- Homonymy : 동일한 형식 + 다른 의미
	- 말(언어) - 말(동물)
- Polysemy : 동일한 형식 + 관련 있는 의미
	- 다리(책상) - 다리(지게)
- 단어의 의미 중의성 해소
- Synonymy : 다른 형식 + 동일한 의미
	- 가수 - 보컬
- Hyponymy : 상하 관계
	- 식사 - 아침 식사

### 특징 2

- 단어 단위의 텍스트 분석은 가장 보편적인 방법으로 여겨져 왔고  
	수많은 기법들이 단어를 기반으로 해서 고안됨
	- 품사 태깅, 개체명 인식, 철자 교정 등
- 서양 언어는 단어 단위로 분석하기 적합함
	- 한국어는 의미 단위의 다른 개념을 가짐
	- 의미에는 어간이 있고 어미가 있으므로 어미를 잘라내야 함
	- 복합 명사 구분
	- 중국어는 스페이스가 없으므로 의미론적으로 단어를 잘라야 함

### Tokenization

- 문헌 단위의 문자열이 주어졌을 때 token들로 문자열을 조각 내는 방법
- 구두점 등 불필요한 글자들을 제외하기도 함
- 영어는 단어에 조사가 붙지 않아 한글보다 tokenization이 쉬움

### 용어 정의

- Word
	- 구분된 문자열
- Term
	- Normalized된 단어 (대소문자, 형태, 철자 등)
	- Word와 동일하게 쓰이기도 함
- Token
	- 유용한 의미적 단위로 함께 모여지는 일련의 문자열
	- 구분 기호 사이의 글자 시퀀스
- Type
	- 같은 문자열을 포함하고 있는 모든 token 들을 표현하는 클래스

### 개념

- 불용어 (Stop word)
	- 정보를 전달하지 않는 단어
	- 기능적인 역할을 함
	- 텍스트 분석을 할 때 더 나은 결과를 내기 위해 불용어를 삭제함
	- 영어 : the, a, in, about ... (관사, 전치사, 주어 등)
	- 한국어 : 있, 않, 없, … (조사, 어미 등)
- 품사 태깅 (POS tagging)
	- 문장에서 각각의 단어를 해당하는 품사로 레이블링하는 작업
	- 하나의 단어가 여러 품사를 갖는 모호성을 가질 수 있으며  
		이러한 품사의 모호성을 해소하는 과정(Kroeger, 2005)
	- 어느 단어 전에 왔는지, 어느 단어 다음에 왔는지 보고 판별
	- 문장에 사용된 형태소들의 품사를 파악하고 문장의 구조도 파악할 수 있음

### 품사 태깅 방법

- 규칙 기반 기법
	- 사전을 사용해서 각각의 단어에 그 단어가 가질 수 있는 품사 리스트를 부여
	- 수작업으로 만든 대량의 규칙을 이용해서 품사의 리스트에서 해당 단어에  맞는 하나의 품사를 선택 (사전의 규칙에 맞지 않는 태그 삭제)
	- 한글 - 세종 말뭉치, 품사 사전
- Stochastic 기반 기법(기계 학습)
	- 각각의 단어의 품사 결정을 해당 단어의 학습 데이터에서 가장 일반적인 품사로 함
	- 히든 마르코프 모델(Hidden Markov Model : HMM)
		- 모든 가능한 태그 순열 중에서 문헌집단 내에 주어진 단어들의 순열
		- (observation sequence)에서 가장 가능성이 있는 태그열을 찾음
	- Conditional Random Field

## 8. Zipf’s 법칙

- 어떠한 자연어 말뭉치 표현에 나타나는 단어들을 그 사용 빈도가 높은 순서대로 정렬한다면,
	모든 단어들의 사용 빈도는 해당 단어의 순위에 반비례함
- Pareto distrubutions의 한 질의
	- 고빈도 단어 - 적게
	- 저빈도 단어 - 길게 Long tail
- 가장 사용 빈도가 높은 단어는 두 번째 단어보다 빈도가 약 두 배 높으며,  
	세 번째 단어보다는 빈도가 약 세 배 높다.
- Zipf’s 법칙은 어느 문헌집단에서나 나타남

### N개의 요소들 가운데 순위가 k번째인 요소의 사용 빈도

- f(k; s, N) = 1 / k^8 / 시그마(N, n=1) (1 / n^8)
- N : 요소의 숫자
- k : 요소의 순위
- s : 분포의 특성을 나타내는 지수값

## 9. 구 단위 텍스트 분석

- 구 (단어 기반 n-gram, proximity features)
	- 주어진 단어와 가장 가까이에 있는 단어들의 열

### 텍스트 단위화(Text Chunking)

- 텍스트를 어휘적으로 상호 관련 있는 단어들로 나누는 자연어 처리의 한 기법  
	(Ramshaw and Marcus, 1999)
- Shallow-parsing
- 명사구는 동사의 주체나 객체가 될 수 있는 요소임
- 동사구는 조동사, 동사 수식어들을 포함하는 요소임

### 텍스트 표현 방법

- 트리 구조 : 각각의 단어에 품사 태깅을 하고 그것을 바탕으로 텍스트를 단위화함  
	(Full parsing의 일종)
- 품사를 이용해서 할 수도 있습니다.
- 태그 : IOB 또는 BOI방식
    - B : Beginning (중요)
    - I : Intermediate (중요)
    - O : Other (기타)

### N-gram

- 주어진 텍스트나 음성의 연속된 일련의 열
- N은 사용한 term의 개수를 기준으로 함
	- Uni-gram : 1 term
	- Bi-gram : 2 terms
	- Tri-gram : 3 terms
- N-gram은 언어 모델링에 쓰일 때 적합
